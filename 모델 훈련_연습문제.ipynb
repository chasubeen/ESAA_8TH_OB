{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chasubeen/ESAA_8th_OB/blob/Week_2/%EB%AA%A8%EB%8D%B8%20%ED%9B%88%EB%A0%A8_%EC%97%B0%EC%8A%B5%EB%AC%B8%EC%A0%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **| 모델 훈련 연습 문제**\n",
        "___\n",
        "- 출처 : 핸즈온 머신러닝 Ch04 연습문제 1, 5, 9, 10\n",
        "- 개념 문제의 경우 텍스트 셀을 추가하여 정답을 적어주세요."
      ],
      "metadata": {
        "id": "zCu72vDHGMHo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1. 수백만 개의 특성을 가진 훈련 세트에서는 어떤 선형 회귀 알고리즘을 사용할 수 있을까요?**\n",
        "___\n"
      ],
      "metadata": {
        "id": "j3g-_Dq9GiuT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 답안\n",
        "- 확률적 경사 하강법(SGD)\n",
        "- 미니배치 경사 하강법\n",
        "- 단, SGD는 매 스텝에서 한 개의 샘플만을 선택하기에, 모델이 편향된 학습을 할 수 있다는 위험성이 있음(불안정함)\n",
        "> 미니배치 경사 하강법이 좀 더 타당해 보인다."
      ],
      "metadata": {
        "id": "wmFQqEGgIhtG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2. 배치 경사 하강법을 사용하고 에포크마다 검증 오차를 그래프로 나타내봤습니다. 검증 오차가 일정하게 상승되고 있다면 어떤 일이 일어나고 있는 걸까요? 이 문제를 어떻게 해결할 수 있나요?**\n",
        "___"
      ],
      "metadata": {
        "id": "-pDjW5XcHPOt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 가정 1) 너무 높은 학습률 -> 알고리즘 발산 가능성\n",
        "  - train loss로 같이 증가하는 경우\n",
        "- 가정 2) 과적합\n",
        "  - 모델이 훈련 set에만 너무 최적화되어 학습됨"
      ],
      "metadata": {
        "id": "Whb3ne0FJPF5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3. 릿지 회귀를 사용했을 때 훈련 오차가 검증 오차가 거의 비슷하고 둘 다 높았습니다. 이 모델에는 높은 편향이 문제인가요, 아니면 높은 분산이 문제인가요? 규제 하이퍼파라미터 $\\alpha$를 증가시켜야 할까요 아니면 줄여야 할까요?**\n",
        "___"
      ],
      "metadata": {
        "id": "nM7JbsLoy7b7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 문제: 높은 편향\n",
        "  - 모델이 훈련 set에 과소적합됨\n",
        "> 규제 하이퍼 파라미터인 alpha를 감소시켜야 함"
      ],
      "metadata": {
        "id": "UY78N4lyJQGz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4. 다음과 같이 사용해야 하는 이유는?**\n",
        "___\n",
        "- 평범한 선형 회귀(즉, 아무런 규제가 없는 모델) 대신 릿지 회귀\n",
        "- 릿지 회귀 대신 라쏘 회귀\n",
        "- 라쏘 회귀 대신 엘라스틱넷"
      ],
      "metadata": {
        "id": "C8tARu-ZzOGx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) 규제가 있는 모델이 일반적으로 규제가 없는 모델에 비해 성능이 좋음  \n",
        "\n",
        "2) 라쏘: l1 penalty, 릿지: l2 penalty  \n",
        "  - 중요도가 낮은 특성은 없애주는 효과를 줄 수 있음\n",
        "    - 특성 수가 많은 데이터 학습의 경우 차원의 저주 문제를 어느 정도 해결해 줄 도 있음\n",
        "  - 몇 개의 특성만이 유용할 것이라는 확신이 들면 라쏘를 사용하면 됨\n",
        "    - 그게 아니라면 일단 릿지도 해보자.  \n",
        "\n",
        "3) 엘라스틱넷: 릿지 + 라쏘  \n",
        "  - 적당히 절충된 모델이라 라쏘가 불규칙하게 튀는 경우를 방지해 줌\n",
        "  - 라쏘에 가깝게 활용하고 싶다면 l1_penalty를 1에 가깝게 주면 됨\n"
      ],
      "metadata": {
        "id": "eBcHqZwtJRM4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **추가) 조기 종료를 사용한 배치 경사 하강법으로 소프트맥스 회귀를 구현해보세요(사이킷런은 사용하지 마세요)**\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "QIZpOEYJVIAV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### 소프트맥스 함수(사용자 정의 함수)\n",
        "\n",
        "def softmax(logits):\n",
        "  exps = np.exp(logits)\n",
        "  exp_sums = np.sum(exps, axis=1, keepdims=True)\n",
        "  return exps / exp_sums"
      ],
      "metadata": {
        "id": "RfYYUy2IJjEW"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 샘플 데이터 생성\n",
        "# iris 데이터 활용\n",
        "\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Iris 데이터 로드\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# 데이터 분리: 학습, 검증, 테스트 데이터\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
      ],
      "metadata": {
        "id": "G3Q-MtK8JR5K"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 초기 하이퍼파라미터 설정\n",
        "\n",
        "learning_rate = 0.01 # 학습률\n",
        "num_epochs = 1000 # 반복 횟수\n",
        "early_stopping_round = 10 # 조기 종료 횟수\n",
        "prev_loss = float(\"inf\") # 초기 손실값\n",
        "patience = 0 # 얼마나 기다려 줄 것인가"
      ],
      "metadata": {
        "id": "08_ONna0J_ee"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 가중치 초기화\n",
        "\n",
        "W = np.random.rand(X.shape[1], len(np.unique(y)))"
      ],
      "metadata": {
        "id": "Q1UmNq8iKRqY"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 검증 손실을 저장할 변수\n",
        "\n",
        "best_val_loss = float(\"inf\")\n",
        "best_W = None"
      ],
      "metadata": {
        "id": "Pit7lLE_Q_XJ"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    ## 예측 계산\n",
        "    train_scores = np.dot(X_train, W)\n",
        "    train_probs = softmax(train_scores)\n",
        "\n",
        "    val_scores = np.dot(X_val, W)\n",
        "    val_probs = softmax(val_scores)\n",
        "\n",
        "    ## 손실 계산\n",
        "    # 크로스 엔트로피 손실 계산\n",
        "    train_loss = -np.log(train_probs[range(len(X_train)), y_train]).mean()\n",
        "\n",
        "    val_loss = -np.log(val_probs[range(len(X_val)), y_val]).mean()\n",
        "\n",
        "    ## 학습 상황 출력\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Epoch {epoch}: Train Loss {train_loss}, Val Loss {val_loss}\")\n",
        "\n",
        "    # Early Stopping Check\n",
        "    if val_loss >= best_val_loss:\n",
        "        patience += 1\n",
        "        if patience >= early_stopping_round:\n",
        "            print(\"Early stopping!\")\n",
        "            break\n",
        "    else:\n",
        "        patience = 0\n",
        "        best_val_loss = val_loss\n",
        "        best_W = W.copy()\n",
        "\n",
        "    ## 기울기(gradient) 계산\n",
        "    dscores = train_probs\n",
        "    dscores[range(len(X_train)), y_train] -= 1\n",
        "    dscores /= len(X_train)\n",
        "\n",
        "    ## 가중치 업데이트\n",
        "    dW = np.dot(X_train.T, dscores)\n",
        "    W -= learning_rate * dW"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdET-QIOLP2V",
        "outputId": "7ee8b5f0-e568-4b26-f263-fdc1cc787f0b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Train Loss 2.666016951770774, Val Loss 2.3009781899248156\n",
            "Epoch 10: Train Loss 1.6438747405927778, Val Loss 1.6337916720911592\n",
            "Epoch 20: Train Loss 1.398724480201496, Val Loss 1.494065083190535\n",
            "Epoch 30: Train Loss 1.3020908032874627, Val Loss 1.3854257450926633\n",
            "Epoch 40: Train Loss 1.218375718862017, Val Loss 1.2757823558967216\n",
            "Epoch 50: Train Loss 1.144391434800491, Val Loss 1.177702477275301\n",
            "Epoch 60: Train Loss 1.079474050826249, Val Loss 1.0921965963818827\n",
            "Epoch 70: Train Loss 1.0227731489050478, Val Loss 1.0182676188681656\n",
            "Epoch 80: Train Loss 0.97333505832422, Val Loss 0.9545444234421183\n",
            "Epoch 90: Train Loss 0.9302009770226145, Val Loss 0.8996211123246904\n",
            "Epoch 100: Train Loss 0.8924718623342165, Val Loss 0.852181818988229\n",
            "Epoch 110: Train Loss 0.8593427577560608, Val Loss 0.8110556313209759\n",
            "Epoch 120: Train Loss 0.8301147074846094, Val Loss 0.7752335820079473\n",
            "Epoch 130: Train Loss 0.8041927468771852, Val Loss 0.743863977530561\n",
            "Epoch 140: Train Loss 0.7810766098629794, Val Loss 0.716236914434963\n",
            "Epoch 150: Train Loss 0.7603485423167795, Val Loss 0.6917648216239682\n",
            "Epoch 160: Train Loss 0.741660765119372, Val Loss 0.6699628752148306\n",
            "Epoch 170: Train Loss 0.7247238720686975, Val Loss 0.6504311561311424\n",
            "Epoch 180: Train Loss 0.7092966859390554, Val Loss 0.6328392521860899\n",
            "Epoch 190: Train Loss 0.6951776786194551, Val Loss 0.6169133841302014\n",
            "Epoch 200: Train Loss 0.6821978569593355, Val Loss 0.6024258435444092\n",
            "Epoch 210: Train Loss 0.6702149328424353, Val Loss 0.5891864224979214\n",
            "Epoch 220: Train Loss 0.6591085766767746, Val Loss 0.5770355004930047\n",
            "Epoch 230: Train Loss 0.6487765646195223, Val Loss 0.565838482280421\n",
            "Epoch 240: Train Loss 0.6391316532737427, Val Loss 0.5554813235099896\n",
            "Epoch 250: Train Loss 0.6300990419965954, Val Loss 0.5458669264954545\n",
            "Epoch 260: Train Loss 0.6216143079832845, Val Loss 0.5369122297113401\n",
            "Epoch 270: Train Loss 0.6136217211986411, Val Loss 0.528545849941145\n",
            "Epoch 280: Train Loss 0.6060728645963356, Val Loss 0.5207061650529222\n",
            "Epoch 290: Train Loss 0.5989255000805098, Val Loss 0.5133397487799923\n",
            "Epoch 300: Train Loss 0.5921426327516398, Val Loss 0.5064000874874689\n",
            "Epoch 310: Train Loss 0.5856917356196795, Val Loss 0.4998465235814242\n",
            "Epoch 320: Train Loss 0.5795441046180694, Val Loss 0.493643381749002\n",
            "Epoch 330: Train Loss 0.5736743198078705, Val Loss 0.4877592432636942\n",
            "Epoch 340: Train Loss 0.5680597934514142, Val Loss 0.4821663406864059\n",
            "Epoch 350: Train Loss 0.5626803894264406, Val Loss 0.47684005086683373\n",
            "Epoch 360: Train Loss 0.5575181014576058, Val Loss 0.4717584685367607\n",
            "Epoch 370: Train Loss 0.5525567800306482, Val Loss 0.46690204624902787\n",
            "Epoch 380: Train Loss 0.5477818997574159, Val Loss 0.4622532891565393\n",
            "Epoch 390: Train Loss 0.5431803604807054, Val Loss 0.45779649530245903\n",
            "Epoch 400: Train Loss 0.5387403166271423, Val Loss 0.45351753382781435\n",
            "Epoch 410: Train Loss 0.5344510302973119, Val Loss 0.4494036548908427\n",
            "Epoch 420: Train Loss 0.5303027443743388, Val Loss 0.44544332620709676\n",
            "Epoch 430: Train Loss 0.5262865725738266, Val Loss 0.44162609201782954\n",
            "Epoch 440: Train Loss 0.5223944038798897, Val Loss 0.4379424510211633\n",
            "Epoch 450: Train Loss 0.5186188192378383, Val Loss 0.43438375039095484\n",
            "Epoch 460: Train Loss 0.5149530187228234, Val Loss 0.430942093489553\n",
            "Epoch 470: Train Loss 0.5113907576903484, Val Loss 0.4276102592743819\n",
            "Epoch 480: Train Loss 0.5079262906509129, Val Loss 0.424381631721583\n",
            "Epoch 490: Train Loss 0.5045543218066271, Val Loss 0.42125013785632615\n",
            "Epoch 500: Train Loss 0.5012699613499934, Val Loss 0.4182101931996307\n",
            "Epoch 510: Train Loss 0.49806868676029337, Val Loss 0.4152566536242592\n",
            "Epoch 520: Train Loss 0.4949463084460122, Val Loss 0.4123847727642895\n",
            "Epoch 530: Train Loss 0.49189893917642485, Val Loss 0.40959016424995504\n",
            "Epoch 540: Train Loss 0.48892296682510605, Val Loss 0.4068687681456723\n",
            "Epoch 550: Train Loss 0.4860150300152192, Val Loss 0.40421682105851636\n",
            "Epoch 560: Train Loss 0.48317199631323415, Val Loss 0.4016308294596865\n",
            "Epoch 570: Train Loss 0.48039094266581966, Val Loss 0.3991075458250958\n",
            "Epoch 580: Train Loss 0.4776691378155969, Val Loss 0.39664394725513963\n",
            "Epoch 590: Train Loss 0.47500402646631196, Val Loss 0.3942372162794741\n",
            "Epoch 600: Train Loss 0.4723932149978019, Val Loss 0.3918847235916655\n",
            "Epoch 610: Train Loss 0.46983445855667577, Val Loss 0.3895840124918946\n",
            "Epoch 620: Train Loss 0.46732564937056814, Val Loss 0.38733278484442607\n",
            "Epoch 630: Train Loss 0.46486480615272113, Val Loss 0.3851288883810618\n",
            "Epoch 640: Train Loss 0.4624500644799392, Val Loss 0.38297030520285236\n",
            "Epoch 650: Train Loss 0.46007966804107575, Val Loss 0.38085514135053217\n",
            "Epoch 660: Train Loss 0.45775196066541646, Val Loss 0.3787816173298387\n",
            "Epoch 670: Train Loss 0.45546537905095263, Val Loss 0.3767480594914882\n",
            "Epoch 680: Train Loss 0.45321844612176543, Val Loss 0.3747528921773923\n",
            "Epoch 690: Train Loss 0.45100976495181466, Val Loss 0.3727946305549709\n",
            "Epoch 700: Train Loss 0.44883801319945366, Val Loss 0.370871874070371\n",
            "Epoch 710: Train Loss 0.44670193800317853, Val Loss 0.3689833004592263\n",
            "Epoch 720: Train Loss 0.4446003512945065, Val Loss 0.367127660260431\n",
            "Epoch 730: Train Loss 0.4425321254886563, Val Loss 0.3653037717844028\n",
            "Epoch 740: Train Loss 0.44049618951787467, Val Loss 0.3635105164925751\n",
            "Epoch 750: Train Loss 0.43849152517594675, Val Loss 0.3617468347494977\n",
            "Epoch 760: Train Loss 0.43651716374569743, Val Loss 0.3600117219130096\n",
            "Epoch 770: Train Loss 0.43457218288416816, Val Loss 0.3583042247315483\n",
            "Epoch 780: Train Loss 0.4326557037427196, Val Loss 0.35662343802086044\n",
            "Epoch 790: Train Loss 0.4307668883015711, Val Loss 0.354968501595187\n",
            "Epoch 800: Train Loss 0.42890493690032094, Val Loss 0.3533385974305205\n",
            "Epoch 810: Train Loss 0.4270690859477765, Val Loss 0.35173294703973973\n",
            "Epoch 820: Train Loss 0.42525860579603275, Val Loss 0.3501508090414223\n",
            "Epoch 830: Train Loss 0.4234727987651696, Val Loss 0.34859147690588904\n",
            "Epoch 840: Train Loss 0.42171099730621714, Val Loss 0.34705427686362034\n",
            "Epoch 850: Train Loss 0.41997256229117996, Val Loss 0.3455385659625794\n",
            "Epoch 860: Train Loss 0.41825688141995304, Val Loss 0.3440437302622493\n",
            "Epoch 870: Train Loss 0.41656336773486585, Val Loss 0.34256918315330886\n",
            "Epoch 880: Train Loss 0.41489145823443846, Val Loss 0.3411143637928886\n",
            "Epoch 890: Train Loss 0.4132406125786673, Val Loss 0.33967873564626333\n",
            "Epoch 900: Train Loss 0.41161031187884195, Val Loss 0.3382617851266394\n",
            "Epoch 910: Train Loss 0.41000005756549035, Val Loss 0.33686302032545445\n",
            "Epoch 920: Train Loss 0.4084093703286097, Val Loss 0.3354819698262513\n",
            "Epoch 930: Train Loss 0.4068377891248269, Val Loss 0.33411818159579354\n",
            "Epoch 940: Train Loss 0.40528487024658927, Val Loss 0.3327712219466429\n",
            "Epoch 950: Train Loss 0.4037501864488871, Val Loss 0.33144067456588894\n",
            "Epoch 960: Train Loss 0.40223332612938345, Val Loss 0.3301261396051815\n",
            "Epoch 970: Train Loss 0.4007338925581601, Val Loss 0.32882723282761644\n",
            "Epoch 980: Train Loss 0.3992515031535934, Val Loss 0.3275435848073774\n",
            "Epoch 990: Train Loss 0.39778578880115306, Val Loss 0.32627484017838887\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- loss가 잘 감소하는 것을 확인할 수 있음"
      ],
      "metadata": {
        "id": "jBdlP6CAQEyj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 예측\n",
        "test_scores = np.dot(X_test, best_W)\n",
        "test_probs = softmax(test_scores)\n",
        "y_pred = np.argmax(test_probs, axis=1)\n",
        "\n",
        "## 평가\n",
        "accuracy = np.mean(y_pred == y_test)\n",
        "print(f\"Test Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eioSCrfoQNCa",
        "outputId": "9d69cff2-e8db-4077-c8aa-b7c6d1e17d2c"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.9666666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **전체 프로세스**\n",
        "1. **예측 계산**: 현재의 모델 가중치를 사용하여 학습 데이터의 예측 점수를 계산하고, 소프트맥스 함수를 적용하여 클래스별 확률을 얻음\n",
        "2. **손실 계산**: 예측과 실제 레이블 간의 차이를 측정하는 손실 함수를 사용하여 학습 데이터/검증 데이터의 손실을 계산\n",
        "3. **Early Stopping 확인**: 검증 손실이 이전 에포크보다 증가하는 경우, 조기 종료를 고려하여 학습을 조기 종료할 수 있음\n",
        "4. **기울기(gradient) 계산**: 손실 함수의 기울기(gradient)를 계산하여 모델 파라미터(가중치)를 업데이트\n",
        "5. **가중치 업데이트**: 기울기를 사용하여 모델의 가중치를 업데이트하여 손실을 최소화\n",
        "6. **최적 모델 선택**: 검증 손실이 최소일 때의 모델 가중치를 최적 모델로 선택\n",
        "7. **반복 종료 확인**: 미리 설정한 학습 횟수(`num_epochs`)를 모두 수행하거나 조기 종료 조건을 만족하면 학습을 종료\n",
        "8. **테스트 평가**: 최적 모델을 사용하여 테스트 데이터에 대한 예측을 수행하고 모델의 최종 성능을 평가"
      ],
      "metadata": {
        "id": "paae14oQSzsd"
      }
    }
  ]
}